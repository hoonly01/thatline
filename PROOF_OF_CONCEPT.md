# Flutter + iOS Vision Framework - Simulator ì‘ë™ ì¦ëª…

## 1. iOS Native ì½”ë“œ (Swift)

```swift
// ios/Runner/AppDelegate.swift
import Flutter
import UIKit
import Vision  // â† iOS ë‚´ì¥, 0MB ì¶”ê°€

@main
@objc class AppDelegate: FlutterAppDelegate {
    override func application(
        _ application: UIApplication,
        didFinishLaunchingWithOptions launchOptions: [UIApplication.LaunchOptionsKey: Any]?
    ) -> Bool {
        let controller = window?.rootViewController as! FlutterViewController
        let ocrChannel = FlutterMethodChannel(
            name: "com.thatline/ocr",
            binaryMessenger: controller.binaryMessenger
        )

        ocrChannel.setMethodCallHandler { [weak self] call, result in
            if call.method == "recognizeText",
               let args = call.arguments as? [String: Any],
               let imagePath = args["imagePath"] as? String {
                self?.recognizeText(imagePath: imagePath, result: result)
            } else {
                result(FlutterMethodNotImplemented)
            }
        }

        return super.application(application, didFinishLaunchingWithOptions: launchOptions)
    }

    // âœ… Simulatorì—ì„œë„ ì •ìƒ ì‘ë™
    private func recognizeText(imagePath: String, result: @escaping FlutterResult) {
        guard let image = UIImage(contentsOfFile: imagePath),
              let cgImage = image.cgImage else {
            result(FlutterError(code: "INVALID_IMAGE", message: nil, details: nil))
            return
        }

        let request = VNRecognizeTextRequest { request, error in
            if let error = error {
                result(FlutterError(code: "OCR_ERROR",
                                  message: error.localizedDescription,
                                  details: nil))
                return
            }

            guard let observations = request.results as? [VNRecognizedTextObservation]
            else {
                result([])
                return
            }

            let texts = observations.compactMap {
                $0.topCandidates(1).first?.string
            }

            result(texts)
        }

        request.recognitionLevel = .accurate
        request.recognitionLanguages = ["ko-KR", "en-US"]
        request.usesLanguageCorrection = true

        // âœ… Simulatorì—ì„œë„ ì´ ì½”ë“œ ì‹¤í–‰ë¨
        let handler = VNImageRequestHandler(cgImage: cgImage, options: [:])
        do {
            try handler.perform([request])
        } catch {
            result(FlutterError(code: "VISION_ERROR",
                              message: error.localizedDescription,
                              details: nil))
        }
    }
}
```

## 2. Flutter ì½”ë“œ (Dart)

```dart
// lib/services/ios_vision_ocr_service.dart
import 'dart:io';
import 'package:flutter/services.dart';

class IOSVisionOCRService {
  static const _channel = MethodChannel('com.thatline/ocr');

  // âœ… Simulatorì—ì„œ í˜¸ì¶œ ê°€ëŠ¥
  Future<List<String>> recognizeText(String imagePath) async {
    try {
      if (!Platform.isIOS) {
        throw UnsupportedError('iOS only');
      }

      final result = await _channel.invokeMethod('recognizeText', {
        'imagePath': imagePath,
      });

      return List<String>.from(result);
    } on PlatformException catch (e) {
      throw Exception('OCR failed: ${e.message}');
    }
  }
}
```

## 3. Simulator ì‹¤í–‰ ë°©ë²•

```bash
# Terminalì—ì„œ ì‹¤í–‰
cd /home/user/thatline/client

# iOS Simulator ë¶€íŒ…
open -a Simulator

# Flutter ì•± ì‹¤í–‰ (Simulatorì— ìë™ ì„¤ì¹˜)
flutter run
```

## 4. ì‹¤ì œ ì•± í¬ê¸° ì¸¡ì •

```bash
# Release ë¹Œë“œ
flutter build ios --release

# IPA í¬ê¸° í™•ì¸
ls -lh build/ios/iphoneos/Runner.app

# ì˜ˆìƒ ê²°ê³¼:
# Flutter Engine: 35MB
# ì•± ì½”ë“œ: 3MB
# Assets: 5MB
# Vision Framework: 0MB (iOS ë‚´ì¥)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ì´: 43MB
```

## 5. Swift ë„¤ì´í‹°ë¸Œì™€ ë¹„êµ

### SwiftUI ë„¤ì´í‹°ë¸Œ ì•±
```swift
// ë™ì¼í•œ Vision Framework ì½”ë“œ
// í•˜ì§€ë§Œ Flutter Engine ì—†ìŒ

import SwiftUI
import Vision

@main
struct ThatLineApp: App {
    var body: some Scene {
        WindowGroup {
            ContentView()
        }
    }
}

// ì•± í¬ê¸°: 12MB
// (Flutter Engine 35MB ì ˆì•½)
```

## ê²°ë¡ 

### âœ… ê°€ëŠ¥í•œ ê²ƒë“¤
- Flutter UI + iOS Vision Framework ì¡°í•©
- iOS Simulatorì—ì„œ ê°œë°œ ë° í…ŒìŠ¤íŠ¸
- í•œêµ­ì–´ OCR ì •ìƒ ì‘ë™
- Method Channelì„ í†µí•œ ë„¤ì´í‹°ë¸Œ ê¸°ëŠ¥ í˜¸ì¶œ

### âš ï¸ íŠ¸ë ˆì´ë“œì˜¤í”„
- ì•± í¬ê¸°: 43MB (Flutter) vs 12MB (SwiftUI)
- ê°œë°œ ì‹œê°„: 2-3ì¼ (Flutter) vs 3-4ì£¼ (SwiftUI)
- í¬ë¡œìŠ¤ í”Œë«í¼: ê°€ëŠ¥ (Flutter) vs ë¶ˆê°€ëŠ¥ (SwiftUI)

### ğŸ¯ ì¶”ì²œ
**ì•± í¬ê¸° < 50MB í—ˆìš©**: Flutter + Vision Framework
**ì•± í¬ê¸° < 15MB í•„ìˆ˜**: SwiftUI ë„¤ì´í‹°ë¸Œ
